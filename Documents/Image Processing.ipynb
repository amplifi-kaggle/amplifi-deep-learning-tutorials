{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-248   -4]\n",
      " [  28 -236]\n",
      " [  -2   14]]\n"
     ]
    }
   ],
   "source": [
    "from scipy import signal as sg\n",
    "\n",
    "print(sg.convolve([[255, 7, 3],\n",
    "                  [212, 240, 4],\n",
    "                  [218, 216, 230]], [[1, -1]], \"valid\")) # mode = full, same, valid\n",
    "\n",
    "# same = pad zeros on borders so that the dimension does not change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.   2.5  4. ]\n",
      "[ 2.5]\n"
     ]
    }
   ],
   "source": [
    "# https://docs.scipy.org/doc/numpy/reference/generated/numpy.convolve.html\n",
    "\n",
    "# Only return the middle values of the convolution. \n",
    "print(sg.convolve([1, 2, 3], [0, 1, 0.5], 'same'))\n",
    "# The two arrays are of the same length, so there is only one position where they completely overlap\n",
    "print(sg.convolve([1, 2, 3], [0, 1, 0.5], 'valid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0]\n",
      " [1 2 1]\n",
      " [0 1 2]]\n"
     ]
    }
   ],
   "source": [
    "print(sg.convolve([[1, 0, 0],\n",
    "                  [0, 1, 0],\n",
    "                  [0, 0, 1]], [[1, 1], [1, 1]], \"same\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1]\n",
      " [1 2]]\n",
      "[[1 1]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(sg.convolve([[1, 0],\n",
    "                  [0, 1]], [[1, 1], [1, 1]], \"same\"))\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "a = np.array([[1, 0],\n",
    "           [0, 1]])\n",
    "b = np.array([[1, 1], [1, 1]])\n",
    "print(np.matmul(a, b.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nimg_name = 'bridge.bmp'\\nname, ext = img_name.split('.')\\nnew_img_name = name + '_new.bmp'\\nprint(new_img_name)\\nimg_arr = np_from_img(img_name)\\nsave_as_img(norm(img_arr), new_img_name)\\n\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# read image\n",
    "def np_from_img(fname):\n",
    "    return np.asarray(Image.open(fname), dtype=np.float32)\n",
    "\n",
    "# write image\n",
    "def save_as_img(ar, fname):\n",
    "    Image.fromarray(ar.round().astype(np.uint8)).save(fname)\n",
    "    \n",
    "# normalization\n",
    "def norm(ar):\n",
    "    return 255*np.absolute(ar)/np.max(ar)\n",
    "\n",
    "# read image file\n",
    "fname = './bridge.bmp'\n",
    "img = np_from_img(fname)\n",
    "print(img.shape)\n",
    "\n",
    "# save blur images\n",
    "save_as_img(norm(sg.convolve(img, [[1, 1, 1], [0, 0, 0], [-1, -1, -1]])), './portal-blur.png')\n",
    "\n",
    "# sharpen\n",
    "save_as_img(norm(sg.convolve(img, [[0, -1, 0], [-1, 6, -1], [0, -1, 0]])), './portal-sharpen.png')\n",
    "\n",
    "# lighter\n",
    "save_as_img(sg.convolve(img, [[0, 0, 0], [0, 2, 0], [0, 0, 0]]), './portal-lighter.png')\n",
    "\n",
    "# save horizontal edges \n",
    "save_as_img(norm(sg.convolve(img, [[1.],[-1.]])), './portal-h.png')\n",
    "\n",
    "# save vertical edges\n",
    "save_as_img(norm(sg.convolve(img, [[1., -1.]])), './portal-v.png')\n",
    "\n",
    "\n",
    "'''\n",
    "img_name = 'bridge.bmp'\n",
    "name, ext = img_name.split('.')\n",
    "new_img_name = name + '_new.bmp'\n",
    "print(new_img_name)\n",
    "img_arr = np_from_img(img_name)\n",
    "save_as_img(norm(img_arr), new_img_name)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-13. -20. -17.]\n",
      " [-18. -24. -18.]\n",
      " [ 13.  20.  17.]]\n"
     ]
    }
   ],
   "source": [
    "# convolution \n",
    "# 2d convolution: \n",
    "#  - http://songho.ca/dsp/convolution/convolution2d_example.html\n",
    "#  - http://www.songho.ca/dsp/convolution/convolution.html#convolution_2d\n",
    "data = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "kernel = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])\n",
    "\n",
    "# kernel as filter\n",
    "def convolve(data, kernel):\n",
    "    h1, w1 = data.shape\n",
    "    h2, w2 = kernel.shape\n",
    "    \n",
    "    out = np.zeros(data.shape)\n",
    "    \n",
    "    # indices for kernel centers\n",
    "    cy, cx = np.divide(data.shape, 2).astype(int) # input.shape[0]/2, input.shape[1]/2\n",
    "    \n",
    "    for i in range(h1):\n",
    "        for j in range(w1):\n",
    "            for y in range(h2):\n",
    "                for x in range(w2):\n",
    "                    if i + y - cy >= 0 and i + y - cy < h1 and j + x - cx >= 0 and j + x - cx < w1:\n",
    "                        out[i, j] += kernel[h2 -1 - y, w2 -1 - x] * data[i + y - cy, j + x - cx]\n",
    "            \n",
    "    return out\n",
    "    \n",
    "print(convolve(data, kernel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[2],\n",
       "        [2]]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([2, 2])\n",
    "a = np.expand_dims(a, axis=1)\n",
    "np.expand_dims(a, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "tf.nn.conv2d(input, filter, strides, padding, name)\n",
    " - input must be a 4d tensor [batch, in_height, in_width, in_channels]\n",
    " - filter/kernel shape: [filter_height, filter_width, in_channels, out_channels]\n",
    " - strides: \n",
    " - padding:\n",
    " - name: \n",
    " \n",
    "Filter의 개수\n",
    " - 일반적으로 영상의 크기가 큰 입력단 근처에 있는 layer는 finite의 개수가 적고, 입력단에서 멀어질수록 filter의\n",
    " 개수는 증가하는 경향이 있음\n",
    " - 각 레이어에서의 연사 시간/량을 비교적 일정하게 유지하여 시스템의 균형을 맞추게 필터의 개수를 조절\n",
    "- \n",
    "\n",
    "Filter의 형태\n",
    " - 일반적으로 32*32 정도의 작은 크기의 입력 영상에 대해선 3x3, 5x5를 자주 사용\n",
    " - 7x7(1개) vs. 3*3 (3개)\n",
    "   - 여러 개의 작은 크기의 필터를 중첩해서 사용하는 것이 좋음\n",
    "   - 여러 개를 중첩하면 중간 단계에 있는 non-linearity를 활용하여 원하는 특징을 더 살릴 수 있음 (filter size smaller -> layer gets deeper)\n",
    "   - 작은 필터를 여러 개 중첩해서 사용하는 것이 연산상 좋음\n",
    "Stride 값\n",
    " - 크기를 조절한다는 면에서 생각할 때 pooling과 유사 (WxH smaller)\n",
    " - stride vs pooling? what's better? -> we don't know. It depends on the model you design.\n",
    "Padding\n",
    " - 보통 convolution 연산을 하게 되면 경계 처리문제가 생김\n",
    "   \n",
    "   \n",
    "'''\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
