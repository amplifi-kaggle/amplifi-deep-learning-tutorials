n_hid 128, n_noise 50
step 100, train batch D loss 0.048765, G loss 4.440637
step 200, train batch D loss 0.061369, G loss 3.728490
step 300, train batch D loss 0.018717, G loss 4.755102
step 400, train batch D loss 0.025846, G loss 4.738591
step 500, train batch D loss 0.024705, G loss 5.859316
step 600, train batch D loss 0.012940, G loss 7.438181
step 700, train batch D loss 0.008609, G loss 6.532063
step 800, train batch D loss 0.008897, G loss 6.165862
step 900, train batch D loss 0.020470, G loss 8.461068
step 1000, train batch D loss 0.025117, G loss 5.619524
step 1100, train batch D loss 0.060360, G loss 3.763161
step 1200, train batch D loss 0.054539, G loss 4.707729
step 1300, train batch D loss 0.210174, G loss 3.513392
step 1400, train batch D loss 0.024748, G loss 5.742898
step 1500, train batch D loss 0.010081, G loss 5.688883
step 1600, train batch D loss 0.080378, G loss 4.338854
step 1700, train batch D loss 0.174738, G loss 2.866799
step 1800, train batch D loss 0.079017, G loss 3.899233
step 1900, train batch D loss 0.044990, G loss 4.317638
step 2000, train batch D loss 0.028672, G loss 4.772415
step 2100, train batch D loss 0.056782, G loss 4.094722
step 2200, train batch D loss 0.068965, G loss 4.726061
step 2300, train batch D loss 0.060369, G loss 4.697014
step 2400, train batch D loss 0.022272, G loss 5.103025
step 2500, train batch D loss 0.061218, G loss 4.159511
step 2600, train batch D loss 0.102115, G loss 4.435801
step 2700, train batch D loss 0.053527, G loss 4.785743
step 2800, train batch D loss 0.061256, G loss 4.402204
step 2900, train batch D loss 0.120538, G loss 3.634088
step 3000, train batch D loss 0.087514, G loss 4.591132
step 3100, train batch D loss 0.176309, G loss 4.748876
step 3200, train batch D loss 0.372942, G loss 4.133512
step 3300, train batch D loss 0.204354, G loss 4.466297
step 3400, train batch D loss 0.167224, G loss 5.496076
step 3500, train batch D loss 0.238917, G loss 3.857934
step 3600, train batch D loss 0.178749, G loss 4.661358
step 3700, train batch D loss 0.114109, G loss 4.226626
step 3800, train batch D loss 0.146819, G loss 4.771458
step 3900, train batch D loss 0.216621, G loss 4.295009
step 4000, train batch D loss 0.144558, G loss 4.330931
step 4100, train batch D loss 0.263900, G loss 3.536741
step 4200, train batch D loss 0.062045, G loss 5.811382
step 4300, train batch D loss 0.140425, G loss 4.691672
step 4400, train batch D loss 0.164845, G loss 4.117668
step 4500, train batch D loss 0.184605, G loss 4.023246
step 4600, train batch D loss 0.319184, G loss 3.857789
step 4700, train batch D loss 0.251708, G loss 3.519300
step 4800, train batch D loss 0.227575, G loss 3.928199
step 4900, train batch D loss 0.291952, G loss 3.770462
step 5000, train batch D loss 0.324374, G loss 3.547113
step 5100, train batch D loss 0.403429, G loss 3.925253
step 5200, train batch D loss 0.276147, G loss 3.857367
step 5300, train batch D loss 0.240739, G loss 3.654348
step 5400, train batch D loss 0.202961, G loss 4.118294
step 5500, train batch D loss 0.407293, G loss 3.519449
step 5600, train batch D loss 0.362248, G loss 3.145479
step 5700, train batch D loss 0.592347, G loss 2.915527
step 5800, train batch D loss 0.203468, G loss 3.844090
step 5900, train batch D loss 0.448397, G loss 3.117098
step 6000, train batch D loss 0.260296, G loss 3.688804
step 6100, train batch D loss 0.397176, G loss 3.330427
step 6200, train batch D loss 0.203882, G loss 3.593549
step 6300, train batch D loss 0.248257, G loss 3.879480
step 6400, train batch D loss 0.240347, G loss 3.758483
step 6500, train batch D loss 0.385820, G loss 3.142764
step 6600, train batch D loss 0.292069, G loss 4.017467
step 6700, train batch D loss 0.329610, G loss 4.027259
step 6800, train batch D loss 0.319220, G loss 3.480264
step 6900, train batch D loss 0.341266, G loss 3.238842
step 7000, train batch D loss 0.504567, G loss 3.497133
step 7100, train batch D loss 0.467720, G loss 3.154748
step 7200, train batch D loss 0.378754, G loss 3.232802
step 7300, train batch D loss 0.440034, G loss 3.005648
step 7400, train batch D loss 0.289907, G loss 3.275393
step 7500, train batch D loss 0.514931, G loss 3.097620
step 7600, train batch D loss 0.419410, G loss 3.203641
step 7700, train batch D loss 0.275920, G loss 3.217463
step 7800, train batch D loss 0.276989, G loss 2.888135
step 7900, train batch D loss 0.336228, G loss 2.964534
step 8000, train batch D loss 0.285238, G loss 3.180821
step 8100, train batch D loss 0.483947, G loss 2.664793
step 8200, train batch D loss 0.389674, G loss 3.028404
step 8300, train batch D loss 0.289483, G loss 3.149359
step 8400, train batch D loss 0.422555, G loss 3.057937
step 8500, train batch D loss 0.407623, G loss 3.135450
step 8600, train batch D loss 0.678958, G loss 2.722662
step 8700, train batch D loss 0.502574, G loss 2.444633
step 8800, train batch D loss 0.361328, G loss 3.369184
step 8900, train batch D loss 0.406214, G loss 2.786434
step 9000, train batch D loss 0.568958, G loss 2.659714
step 9100, train batch D loss 0.564148, G loss 3.279102
step 9200, train batch D loss 0.423618, G loss 2.871471
step 9300, train batch D loss 0.300826, G loss 3.516074
step 9400, train batch D loss 0.569152, G loss 3.111485
step 9500, train batch D loss 0.536375, G loss 2.761674
step 9600, train batch D loss 0.540178, G loss 2.649810
step 9700, train batch D loss 0.529414, G loss 2.293027
step 9800, train batch D loss 0.486582, G loss 2.963910
step 9900, train batch D loss 0.467600, G loss 3.115286
step 10000, train batch D loss 0.510347, G loss 3.029652
step 10100, train batch D loss 0.408357, G loss 2.443014
step 10200, train batch D loss 0.487236, G loss 3.265774
step 10300, train batch D loss 0.696228, G loss 2.881164
step 10400, train batch D loss 0.397283, G loss 3.088135
step 10500, train batch D loss 0.707815, G loss 2.359099
step 10600, train batch D loss 0.533926, G loss 2.850609
step 10700, train batch D loss 0.527334, G loss 2.947157
step 10800, train batch D loss 0.619639, G loss 2.247068
step 10900, train batch D loss 0.624936, G loss 2.551544
step 11000, train batch D loss 0.506263, G loss 3.271805
step 11100, train batch D loss 0.394873, G loss 2.638101
step 11200, train batch D loss 0.475924, G loss 2.729207
step 11300, train batch D loss 0.499054, G loss 2.668674
step 11400, train batch D loss 0.790311, G loss 2.346967
step 11500, train batch D loss 0.444359, G loss 2.869561
step 11600, train batch D loss 0.670356, G loss 2.638783
step 11700, train batch D loss 0.652728, G loss 2.437499
step 11800, train batch D loss 0.503471, G loss 2.760617
step 11900, train batch D loss 0.344113, G loss 2.960313
step 12000, train batch D loss 0.488356, G loss 2.344032
step 12100, train batch D loss 0.410137, G loss 2.869158
step 12200, train batch D loss 0.495096, G loss 2.742039
step 12300, train batch D loss 0.631289, G loss 2.444146
step 12400, train batch D loss 0.511294, G loss 2.614786
step 12500, train batch D loss 0.557646, G loss 2.666198
step 12600, train batch D loss 0.446584, G loss 2.780592
step 12700, train batch D loss 0.538703, G loss 2.768999
step 12800, train batch D loss 0.429070, G loss 2.599440
step 12900, train batch D loss 0.513454, G loss 2.732016
step 13000, train batch D loss 0.433372, G loss 2.905252
step 13100, train batch D loss 0.553018, G loss 2.409606
step 13200, train batch D loss 0.647370, G loss 2.877033
step 13300, train batch D loss 0.436587, G loss 2.461040
step 13400, train batch D loss 0.679856, G loss 2.221567
step 13500, train batch D loss 0.578239, G loss 2.298146
step 13600, train batch D loss 0.543447, G loss 2.743249
step 13700, train batch D loss 0.639473, G loss 2.407112
step 13800, train batch D loss 0.679807, G loss 2.623861
step 13900, train batch D loss 0.366079, G loss 3.084501
step 14000, train batch D loss 0.710479, G loss 2.213240
step 14100, train batch D loss 0.534112, G loss 2.393158
step 14200, train batch D loss 0.717420, G loss 2.168775
step 14300, train batch D loss 0.532424, G loss 2.630090
step 14400, train batch D loss 0.385867, G loss 2.589228
step 14500, train batch D loss 0.527084, G loss 2.663739
step 14600, train batch D loss 0.685366, G loss 2.063731
step 14700, train batch D loss 0.699352, G loss 1.907612
step 14800, train batch D loss 0.683379, G loss 1.917588
step 14900, train batch D loss 0.718514, G loss 2.254865
step 15000, train batch D loss 0.753300, G loss 2.179045
step 15100, train batch D loss 0.654074, G loss 2.237316
step 15200, train batch D loss 0.586121, G loss 2.115647
step 15300, train batch D loss 0.620169, G loss 2.432008
step 15400, train batch D loss 0.583321, G loss 2.349150
step 15500, train batch D loss 0.628396, G loss 2.071925
step 15600, train batch D loss 0.539185, G loss 2.123808
step 15700, train batch D loss 0.657366, G loss 2.489047
step 15800, train batch D loss 0.696877, G loss 2.278750
step 15900, train batch D loss 0.606313, G loss 2.262110
step 16000, train batch D loss 0.577448, G loss 2.650496
step 16100, train batch D loss 0.657904, G loss 2.024059
step 16200, train batch D loss 0.737791, G loss 1.998750
step 16300, train batch D loss 0.657452, G loss 2.258320
step 16400, train batch D loss 0.602449, G loss 2.147228
step 16500, train batch D loss 0.686985, G loss 1.857440
step 16600, train batch D loss 0.731253, G loss 1.926379
step 16700, train batch D loss 0.677657, G loss 2.140599
step 16800, train batch D loss 0.712475, G loss 2.064252
step 16900, train batch D loss 0.523867, G loss 2.502209
step 17000, train batch D loss 0.458032, G loss 2.351058
step 17100, train batch D loss 0.582694, G loss 2.101148
step 17200, train batch D loss 0.691446, G loss 2.167642
step 17300, train batch D loss 0.515065, G loss 2.246315
step 17400, train batch D loss 0.467349, G loss 2.339630
step 17500, train batch D loss 0.760550, G loss 2.015898
step 17600, train batch D loss 0.650609, G loss 2.119602
step 17700, train batch D loss 0.702193, G loss 2.042000
step 17800, train batch D loss 0.632563, G loss 2.064139
step 17900, train batch D loss 0.680723, G loss 2.329481
step 18000, train batch D loss 0.674771, G loss 2.249396
step 18100, train batch D loss 0.606877, G loss 2.113768
step 18200, train batch D loss 0.680193, G loss 2.128978
step 18300, train batch D loss 0.549423, G loss 2.552211
step 18400, train batch D loss 0.619673, G loss 2.120898
step 18500, train batch D loss 0.662695, G loss 2.110472
step 18600, train batch D loss 0.608108, G loss 2.261244
step 18700, train batch D loss 0.665709, G loss 1.937629
step 18800, train batch D loss 0.743560, G loss 2.296476
step 18900, train batch D loss 0.581409, G loss 2.478703
step 19000, train batch D loss 0.841966, G loss 1.813333
step 19100, train batch D loss 0.642799, G loss 2.317914
step 19200, train batch D loss 0.638011, G loss 2.154622
step 19300, train batch D loss 0.759418, G loss 2.131102
step 19400, train batch D loss 0.760109, G loss 1.859499
step 19500, train batch D loss 0.716381, G loss 2.073243
step 19600, train batch D loss 0.755579, G loss 2.135832
step 19700, train batch D loss 0.703005, G loss 1.749874
step 19800, train batch D loss 0.768136, G loss 2.223620
step 19900, train batch D loss 0.689885, G loss 1.884494
step 20000, train batch D loss 0.541800, G loss 2.330452
